{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPyOpt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EVENTS = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_dist = 3.6\n",
    "radius = 2\n",
    "\n",
    "space = [{'name': 'pitch', 'type': 'continuous', 'domain': (min_dist, min_dist)},\\\n",
    "         {'name': 'yoffset_layer', 'type': 'continuous', 'domain': (min_dist/2, min_dist)},\\\n",
    "         {'name': 'yoffset_plane', 'type': 'continuous', 'domain': (min_dist*0.25, min_dist*1.25)},\\\n",
    "         {'name': 'zshift_layer', 'type': 'continuous', 'domain': (1, 15)},\\\n",
    "         {'name': 'zshift_plane', 'type': 'continuous', 'domain': (1, 15)},\\\n",
    "         {'name': 'zshift_view', 'type': 'continuous', 'domain': (10, 15)},\\\n",
    "         {'name': 'alpha', 'type': 'continuous', 'domain': (5, 15)}]\n",
    "\n",
    "constraints = [{'name': 'constr_1', 'constrain': '-(x[:,0]-x[:,1])**2-x[:,3]**2+'+str(radius)+'**2'},\\\n",
    "               {'name': 'constr_2', 'constrain': '-(x[:,1]-x[:,2])**2-(x[:,3]-x[:,4])**2+'+str(radius)+'**2'},\\\n",
    "               {'name': 'constr_3', 'constrain': 'x[:,3]+x[:,4]+'+str(radius)+'-x[:,5]'},\n",
    "               {'name': 'constr_4', 'constrain': 'x[:,3]+'+str(radius)+'-x[:,4]'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feasible_region = GPyOpt.Design_space(space=space, constraints=constraints)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import skygrid client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "from disneylandClient import (\n",
    "    new_client,\n",
    "    Job,\n",
    "    RequestWithId,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUS_IN_PROCESS = set([\n",
    "    Job.PENDING,\n",
    "    Job.PULLED,\n",
    "    Job.RUNNING,\n",
    "])\n",
    "STATUS_FINAL = set([\n",
    "    Job.COMPLETED,\n",
    "    Job.FAILED,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_descriptor(point):\n",
    "    \n",
    "    pitch, yoffset_layer, yoffset_plane, zshift_layer, zshift_plane, zshift_view, alpha = point\n",
    "    \n",
    "    cmd = \"/opt/disney-run.sh python /opt/objective.py --pitch \"+str(pitch)+\" --yoffset_layer \"+str(yoffset_layer)+\\\n",
    "        \" --yoffset_plane \"+str(yoffset_plane)+\" --zshift_layer \"+str(zshift_layer)+\" --zshift_plane \"+\\\n",
    "        str(zshift_plane)+\" --zshift_view \"+str(zshift_view)+\" --alpha \"+str(int(alpha))+\\\n",
    "        \" --nEvents \"+str(N_EVENTS)+\" --method FH\"\n",
    "\n",
    "    descriptor = {\n",
    "        \"input\": [],\n",
    "\n",
    "        \"container\": {\n",
    "            \"workdir\": \"\",\n",
    "            \"name\": \"oleg94/ship_metric:latest\",\n",
    "            \"cpu_needed\": 1,\n",
    "            \"max_memoryMB\": 4096,\n",
    "            \"min_memoryMB\": 1024,\n",
    "            \"cmd\": cmd,\n",
    "        },\n",
    "\n",
    "        \"required_outputs\": {\n",
    "            \"output_uri\": \"none:\",\n",
    "            \"file_contents\": [\n",
    "                {\"file\": \"output.txt\", \"to_variable\": \"out\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 20\n",
    "n_initial_design = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_design = GPyOpt.experiment_design.initial_design('random', feasible_region, n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_objective = np.zeros(n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stub = new_client()\n",
    "jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 started.\n",
      "0  pushed\n",
      "1  pushed\n",
      "2  pushed\n",
      "3  pushed\n",
      "4  pushed\n",
      "5  pushed\n",
      "6  pushed\n",
      "7  pushed\n",
      "8  pushed\n",
      "9  pushed\n",
      "10  pushed\n",
      "11  pushed\n",
      "12  pushed\n",
      "13  pushed\n",
      "14  pushed\n",
      "15  pushed\n",
      "16  pushed\n",
      "17  pushed\n",
      "18  pushed\n",
      "19  pushed\n",
      "Finished jobs: 0 Running jobs: 19 Pending jobs: 0\n",
      "Finished jobs: 0 Running jobs: 20 Pending jobs: 0\n",
      "Finished jobs: 4 Running jobs: 16 Pending jobs: 0\n",
      "Finished jobs: 6 Running jobs: 14 Pending jobs: 0\n",
      "Finished jobs: 8 Running jobs: 12 Pending jobs: 0\n",
      "Finished jobs: 9 Running jobs: 11 Pending jobs: 0\n",
      "Finished jobs: 10 Running jobs: 10 Pending jobs: 0\n",
      "Finished jobs: 12 Running jobs: 8 Pending jobs: 0\n",
      "Finished jobs: 15 Running jobs: 5 Pending jobs: 0\n",
      "Finished jobs: 16 Running jobs: 4 Pending jobs: 0\n",
      "Finished jobs: 17 Running jobs: 3 Pending jobs: 0\n",
      "Finished jobs: 18 Running jobs: 2 Pending jobs: 0\n",
      "Finished jobs: 19 Running jobs: 1 Pending jobs: 0\n",
      "Finished jobs: 20 Running jobs: 0 Pending jobs: 0\n"
     ]
    }
   ],
   "source": [
    "init_d_i = 0\n",
    "\n",
    "for epoch in range(n_initial_design // n_estimators):\n",
    "    \n",
    "    print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "    \n",
    "    epoch_jobs = [0] * n_estimators\n",
    "    \n",
    "    for k in range(n_estimators):\n",
    "        descriptor = return_descriptor(initial_design[init_d_i])\n",
    "        init_d_i += 1\n",
    "        epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "        epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "        print(k, \" pushed\")\n",
    "    \n",
    "    prev_number_of_finished_jobs = 0\n",
    "    prev_number_of_running_jobs = 0\n",
    "    prev_number_of_pending_jobs = 0\n",
    "    \n",
    "    while True:\n",
    "        for k in range(n_estimators):\n",
    "            epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "        \n",
    "        number_of_finished_jobs = 0\n",
    "        number_of_running_jobs = 0\n",
    "        number_of_pending_jobs = 0\n",
    "        for k in range(n_estimators):\n",
    "            if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                number_of_finished_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.PENDING:\n",
    "                number_of_pending_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.RUNNING:\n",
    "                number_of_running_jobs += 1\n",
    "                \n",
    "        if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "            print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                  \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                  \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "            prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "            prev_number_of_running_jobs = number_of_running_jobs\n",
    "            prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "            \n",
    "        if number_of_finished_jobs == n_estimators:\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    \n",
    "    jobs += epoch_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init_design = pd.DataFrame(initial_design, columns=['pitch', 'yoffset_layer', 'yoffset_plane', 'zshift_layer', 'zshift_plane', 'zshift_view', 'alpha'])\n",
    "df_init_design['reconstructible'] = [float(json.loads(re.sub(r\"\\\\\", '', job.output[15:-2]))['reconstructible']) if re.sub(r\"\\\\\", '', job.output[15:-2]) else np.nan for job in jobs]\n",
    "df_init_design['reco_passed_no_clones'] = [float(json.loads(re.sub(r\"\\\\\", '', job.output[15:-2]))['reco_passed_no_clones']) if re.sub(r\"\\\\\", '', job.output[15:-2]) else np.nan for job in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>yoffset_layer</th>\n",
       "      <th>yoffset_plane</th>\n",
       "      <th>zshift_layer</th>\n",
       "      <th>zshift_plane</th>\n",
       "      <th>zshift_view</th>\n",
       "      <th>alpha</th>\n",
       "      <th>reconstructible</th>\n",
       "      <th>reco_passed_no_clones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.938150</td>\n",
       "      <td>1.308505</td>\n",
       "      <td>2.177960</td>\n",
       "      <td>8.956320</td>\n",
       "      <td>14.769643</td>\n",
       "      <td>14.900539</td>\n",
       "      <td>209.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.773143</td>\n",
       "      <td>3.276711</td>\n",
       "      <td>3.424826</td>\n",
       "      <td>7.415540</td>\n",
       "      <td>13.144714</td>\n",
       "      <td>10.052524</td>\n",
       "      <td>163.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.414219</td>\n",
       "      <td>4.044883</td>\n",
       "      <td>2.500408</td>\n",
       "      <td>7.043234</td>\n",
       "      <td>12.051984</td>\n",
       "      <td>6.148368</td>\n",
       "      <td>142.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.985213</td>\n",
       "      <td>2.726884</td>\n",
       "      <td>1.949719</td>\n",
       "      <td>7.242638</td>\n",
       "      <td>11.371076</td>\n",
       "      <td>5.325262</td>\n",
       "      <td>142.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.075053</td>\n",
       "      <td>3.120937</td>\n",
       "      <td>1.942908</td>\n",
       "      <td>6.966538</td>\n",
       "      <td>14.470496</td>\n",
       "      <td>12.965373</td>\n",
       "      <td>170.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pitch  yoffset_layer  yoffset_plane  zshift_layer  zshift_plane  \\\n",
       "0    3.6       2.938150       1.308505      2.177960      8.956320   \n",
       "1    3.6       2.773143       3.276711      3.424826      7.415540   \n",
       "2    3.6       3.414219       4.044883      2.500408      7.043234   \n",
       "3    3.6       2.985213       2.726884      1.949719      7.242638   \n",
       "4    3.6       3.075053       3.120937      1.942908      6.966538   \n",
       "\n",
       "   zshift_view      alpha  reconstructible  reco_passed_no_clones  \n",
       "0    14.769643  14.900539            209.0                  198.0  \n",
       "1    13.144714  10.052524            163.0                  160.0  \n",
       "2    12.051984   6.148368            142.0                  140.0  \n",
       "3    11.371076   5.325262            142.0                  140.0  \n",
       "4    14.470496  12.965373            170.0                  164.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init_design.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part of optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design = pd.read_csv('observations/observations.csv')\n",
    "n_estimators = 10\n",
    "n_epochs = 50\n",
    "stub = new_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "        print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "\n",
    "        step_X = df_init_design[df_init_design.columns[:-1]].values\n",
    "        #because we want to maximize\n",
    "        step_Y = (-df_init_design['reco_passed_no_clones'] / df_initdesign['reconstructible']).values.reshape(-1, 1)\n",
    "        ignored_X = step_X[np.isnan(step_Y.ravel())]\n",
    "        step_X = step_X[~np.isnan(step_Y.ravel())]\n",
    "        step_Y = step_Y[~np.isnan(step_Y.ravel())]\n",
    "        bo = GPyOpt.methods.BayesianOptimization(f=None, domain=space, constraints=constraints, X=step_X,\\\n",
    "                                                 Y=step_Y, initial_design_numdata=20,\\\n",
    "                                                 evaluator_type='local_penalization', batch_size=n_estimators)\n",
    "        \n",
    "        pending_X = list(bo.suggest_next_locations(ignored_X=ignored_X))\n",
    "        \n",
    "        epoch_jobs = [0] * len(pending_X)\n",
    "        for k, new_point in enumerate(pending_X):\n",
    "            descriptor = return_descriptor(new_point)\n",
    "            epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "            epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "        \n",
    "        prev_number_of_finished_jobs = 0\n",
    "        prev_number_of_running_jobs = 0\n",
    "        prev_number_of_pending_jobs = 0\n",
    "\n",
    "        while True:\n",
    "            for k in range(n_estimators):\n",
    "                epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "\n",
    "            number_of_finished_jobs = 0\n",
    "            number_of_running_jobs = 0\n",
    "            number_of_pending_jobs = 0\n",
    "            for k in range(n_estimators):\n",
    "                if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                    number_of_finished_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.PENDING:\n",
    "                    number_of_pending_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.RUNNING:\n",
    "                    number_of_running_jobs += 1\n",
    "\n",
    "            if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "                print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                      \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                      \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "                prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "                prev_number_of_running_jobs = number_of_running_jobs\n",
    "                prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "\n",
    "            if number_of_finished_jobs == n_estimators:\n",
    "                break\n",
    "            time.sleep(10)\n",
    "            \n",
    "        for k, point in enumerate(pending_X):\n",
    "        \n",
    "            reconstructible = float(json.loads(re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]))['reconstructible']) if re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]) else np.nan\n",
    "            reco_passed_no_clones = float(json.loads(re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]))['reco_passed_no_clones']) if re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]) else np.nan\n",
    "            \n",
    "            df_init_design.loc[len(df_init_design)] = list(point)+[reconstructible, reco_passed_no_clones]\n",
    "            df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
