{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GPyOpt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EVENTS = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_dist = 3.6\n",
    "radius = 2\n",
    "\n",
    "space = [{'name': 'pitch', 'type': 'continuous', 'domain': (min_dist, min_dist)},\\\n",
    "         {'name': 'yoffset_layer', 'type': 'continuous', 'domain': (min_dist/2, min_dist)},\\\n",
    "         {'name': 'yoffset_plane', 'type': 'continuous', 'domain': (min_dist*0.25, min_dist*1.25)},\\\n",
    "         {'name': 'zshift_layer', 'type': 'continuous', 'domain': (1, 12)},\\\n",
    "         {'name': 'zshift_plane', 'type': 'continuous', 'domain': (1, 12)},\\\n",
    "         {'name': 'zshift_view', 'type': 'continuous', 'domain': (10, 12)},\\\n",
    "         {'name': 'alpha', 'type': 'continuous', 'domain': (5, 15)}]\n",
    "\n",
    "constraints = [{'name': 'constr_1', 'constrain': '-(x[:,0]-x[:,1])**2-x[:,3]**2+'+str(radius)+'**2'},\\\n",
    "               {'name': 'constr_2', 'constrain': '-(x[:,1]-x[:,2])**2-(x[:,3]-x[:,4])**2+'+str(radius)+'**2'},\\\n",
    "               {'name': 'constr_3', 'constrain': 'x[:,3]+x[:,4]+'+str(radius)+'-x[:,5]'},\n",
    "               {'name': 'constr_4', 'constrain': 'x[:,3]+'+str(radius)+'-x[:,4]'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feasible_region = GPyOpt.Design_space(space=space, constraints=constraints)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import skygrid client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "from disneylandClient import (\n",
    "    new_client,\n",
    "    Job,\n",
    "    RequestWithId,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUS_IN_PROCESS = set([\n",
    "    Job.PENDING,\n",
    "    Job.PULLED,\n",
    "    Job.RUNNING,\n",
    "])\n",
    "STATUS_FINAL = set([\n",
    "    Job.COMPLETED,\n",
    "    Job.FAILED,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_descriptor(point):\n",
    "    \n",
    "    pitch, yoffset_layer, yoffset_plane, zshift_layer, zshift_plane, zshift_view, alpha = point\n",
    "    \n",
    "    cmd = \"/opt/disney-run.sh python /opt/objective.py --pitch \"+str(pitch)+\" --yoffset_layer \"+str(yoffset_layer)+\\\n",
    "        \" --yoffset_plane \"+str(yoffset_plane)+\" --zshift_layer \"+str(zshift_layer)+\" --zshift_plane \"+\\\n",
    "        str(zshift_plane)+\" --zshift_view \"+str(zshift_view)+\" --alpha \"+str(int(alpha))+\\\n",
    "        \" --nEvents \"+str(N_EVENTS)+\" --method FH\"\n",
    "\n",
    "    descriptor = {\n",
    "        \"input\": [],\n",
    "\n",
    "        \"container\": {\n",
    "            \"workdir\": \"\",\n",
    "            \"name\": \"oleg94/ship_metric:03.27\",\n",
    "            \"cpu_needed\": 1,\n",
    "            \"max_memoryMB\": 4096,\n",
    "            \"min_memoryMB\": 1024,\n",
    "            \"cmd\": cmd,\n",
    "        },\n",
    "\n",
    "        \"required_outputs\": {\n",
    "            \"output_uri\": \"none:\",\n",
    "            \"file_contents\": [\n",
    "                {\"file\": \"output.txt\", \"to_variable\": \"out\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "n_initial_design = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_design = GPyOpt.experiment_design.initial_design('random', feasible_region, n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_objective = np.zeros(n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stub = new_client()\n",
    "jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 started.\n",
      "0  pushed\n",
      "1  pushed\n",
      "2  pushed\n",
      "3  pushed\n",
      "4  pushed\n",
      "5  pushed\n",
      "6  pushed\n",
      "7  pushed\n",
      "8  pushed\n",
      "9  pushed\n",
      "10  pushed\n",
      "11  pushed\n",
      "12  pushed\n",
      "13  pushed\n",
      "14  pushed\n",
      "15  pushed\n",
      "16  pushed\n",
      "17  pushed\n",
      "18  pushed\n",
      "19  pushed\n",
      "20  pushed\n",
      "21  pushed\n",
      "22  pushed\n",
      "23  pushed\n",
      "24  pushed\n",
      "25  pushed\n",
      "26  pushed\n",
      "27  pushed\n",
      "28  pushed\n",
      "29  pushed\n",
      "30  pushed\n",
      "31  pushed\n",
      "32  pushed\n",
      "33  pushed\n",
      "34  pushed\n",
      "35  pushed\n",
      "36  pushed\n",
      "37  pushed\n",
      "38  pushed\n",
      "39  pushed\n",
      "Finished jobs: 0 Running jobs: 0 Pending jobs: 40\n",
      "Finished jobs: 0 Running jobs: 40 Pending jobs: 0\n",
      "Finished jobs: 1 Running jobs: 39 Pending jobs: 0\n",
      "Finished jobs: 2 Running jobs: 38 Pending jobs: 0\n",
      "Finished jobs: 3 Running jobs: 37 Pending jobs: 0\n",
      "Finished jobs: 4 Running jobs: 36 Pending jobs: 0\n",
      "Finished jobs: 5 Running jobs: 35 Pending jobs: 0\n",
      "Finished jobs: 6 Running jobs: 34 Pending jobs: 0\n",
      "Finished jobs: 7 Running jobs: 33 Pending jobs: 0\n",
      "Finished jobs: 8 Running jobs: 32 Pending jobs: 0\n"
     ]
    }
   ],
   "source": [
    "init_d_i = 0\n",
    "\n",
    "for epoch in range(n_initial_design // n_estimators):\n",
    "    \n",
    "    print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "    \n",
    "    epoch_jobs = [0] * n_estimators\n",
    "    \n",
    "    for k in range(n_estimators):\n",
    "        descriptor = return_descriptor(initial_design[init_d_i])\n",
    "        init_d_i += 1\n",
    "        epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "        epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "        print(k, \" pushed\")\n",
    "    \n",
    "    prev_number_of_finished_jobs = 0\n",
    "    prev_number_of_running_jobs = 0\n",
    "    prev_number_of_pending_jobs = 0\n",
    "    \n",
    "    while True:\n",
    "        for k in range(n_estimators):\n",
    "            epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "        \n",
    "        number_of_finished_jobs = 0\n",
    "        number_of_running_jobs = 0\n",
    "        number_of_pending_jobs = 0\n",
    "        for k in range(n_estimators):\n",
    "            if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                number_of_finished_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.PENDING:\n",
    "                number_of_pending_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.RUNNING:\n",
    "                number_of_running_jobs += 1\n",
    "                \n",
    "        if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "            print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                  \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                  \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "            prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "            prev_number_of_running_jobs = number_of_running_jobs\n",
    "            prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "            \n",
    "        if number_of_finished_jobs == n_estimators:\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    \n",
    "    jobs += epoch_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design = pd.DataFrame(initial_design, columns=['pitch', 'yoffset_layer', 'yoffset_plane', 'zshift_layer', 'zshift_plane', 'zshift_view', 'alpha'])\n",
    "df_init_design['reconstructible'] = [float(json.loads(re.sub(r\"\\\\\", '', job.output[15:-2]))['reconstructible']) if re.sub(r\"\\\\\", '', job.output[15:-2]) else np.nan for job in jobs]\n",
    "df_init_design['reco_passed_no_clones'] = [float(json.loads(re.sub(r\"\\\\\", '', job.output[15:-2]))['reco_passed_no_clones']) if re.sub(r\"\\\\\", '', job.output[15:-2]) else np.nan for job in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>yoffset_layer</th>\n",
       "      <th>yoffset_plane</th>\n",
       "      <th>zshift_layer</th>\n",
       "      <th>zshift_plane</th>\n",
       "      <th>zshift_view</th>\n",
       "      <th>alpha</th>\n",
       "      <th>reconstructible</th>\n",
       "      <th>reco_passed_no_clones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.436777</td>\n",
       "      <td>1.128810</td>\n",
       "      <td>2.210571</td>\n",
       "      <td>6.893522</td>\n",
       "      <td>11.797108</td>\n",
       "      <td>8.701587</td>\n",
       "      <td>157.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.491098</td>\n",
       "      <td>3.638826</td>\n",
       "      <td>2.318519</td>\n",
       "      <td>6.633024</td>\n",
       "      <td>11.303923</td>\n",
       "      <td>13.511367</td>\n",
       "      <td>135.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.934191</td>\n",
       "      <td>1.723673</td>\n",
       "      <td>1.566266</td>\n",
       "      <td>6.826156</td>\n",
       "      <td>11.784093</td>\n",
       "      <td>8.594912</td>\n",
       "      <td>155.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.372442</td>\n",
       "      <td>2.453974</td>\n",
       "      <td>2.263205</td>\n",
       "      <td>4.947135</td>\n",
       "      <td>11.594591</td>\n",
       "      <td>13.698964</td>\n",
       "      <td>135.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.251162</td>\n",
       "      <td>3.225302</td>\n",
       "      <td>2.697990</td>\n",
       "      <td>5.830484</td>\n",
       "      <td>11.440073</td>\n",
       "      <td>5.547616</td>\n",
       "      <td>147.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pitch  yoffset_layer  yoffset_plane  zshift_layer  zshift_plane  \\\n",
       "0    3.6       3.436777       1.128810      2.210571      6.893522   \n",
       "1    3.6       3.491098       3.638826      2.318519      6.633024   \n",
       "2    3.6       1.934191       1.723673      1.566266      6.826156   \n",
       "3    3.6       3.372442       2.453974      2.263205      4.947135   \n",
       "4    3.6       3.251162       3.225302      2.697990      5.830484   \n",
       "\n",
       "   zshift_view      alpha  reconstructible  reco_passed_no_clones  \n",
       "0    11.797108   8.701587            157.0                  119.0  \n",
       "1    11.303923  13.511367            135.0                   60.0  \n",
       "2    11.784093   8.594912            155.0                  145.0  \n",
       "3    11.594591  13.698964            135.0                  112.0  \n",
       "4    11.440073   5.547616            147.0                   74.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init_design.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part of optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design = pd.read_csv('observations/observations.csv')\n",
    "n_estimators = 20\n",
    "n_epochs = 50\n",
    "stub = new_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 started.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "        print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "\n",
    "        step_X = df_init_design[df_init_design.columns[:-1]].values\n",
    "        #because we want to maximize\n",
    "        step_Y = (-df_init_design['reco_passed_no_clones'] / N_EVENTS).values.reshape(-1, 1)\n",
    "        ignored_X = step_X[np.isnan(step_Y.ravel())]\n",
    "        step_X = step_X[~np.isnan(step_Y.ravel())]\n",
    "        step_Y = step_Y[~np.isnan(step_Y.ravel())]\n",
    "        bo = GPyOpt.methods.BayesianOptimization(f=None, domain=space, constraints=constraints, X=step_X,\\\n",
    "                                                 Y=step_Y, initial_design_numdata=20,\\\n",
    "                                                 evaluator_type='local_penalization', batch_size=n_estimators)\n",
    "        \n",
    "        pending_X = list(bo.suggest_next_locations(ignored_X=ignored_X))\n",
    "        \n",
    "        epoch_jobs = [0] * len(pending_X)\n",
    "        for k, new_point in enumerate(pending_X):\n",
    "            descriptor = return_descriptor(new_point)\n",
    "            epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "            epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "        \n",
    "        prev_number_of_finished_jobs = 0\n",
    "        prev_number_of_running_jobs = 0\n",
    "        prev_number_of_pending_jobs = 0\n",
    "\n",
    "        while True:\n",
    "            for k in range(n_estimators):\n",
    "                epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "\n",
    "            number_of_finished_jobs = 0\n",
    "            number_of_running_jobs = 0\n",
    "            number_of_pending_jobs = 0\n",
    "            for k in range(n_estimators):\n",
    "                if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                    number_of_finished_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.PENDING:\n",
    "                    number_of_pending_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.RUNNING:\n",
    "                    number_of_running_jobs += 1\n",
    "\n",
    "            if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "                print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                      \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                      \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "                prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "                prev_number_of_running_jobs = number_of_running_jobs\n",
    "                prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "\n",
    "            if number_of_finished_jobs == n_estimators:\n",
    "                break\n",
    "            time.sleep(10)\n",
    "            \n",
    "        for k, point in enumerate(pending_X):\n",
    "        \n",
    "            reconstructible = float(json.loads(re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]))['reconstructible']) if re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]) else np.nan\n",
    "            reco_passed_no_clones = float(json.loads(re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]))['reco_passed_no_clones']) if re.sub(r\"\\\\\", '', epoch_jobs[k].output[15:-2]) else np.nan\n",
    "            \n",
    "            df_init_design.loc[len(df_init_design)] = list(point)+[reconstructible, reco_passed_no_clones]\n",
    "            df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
